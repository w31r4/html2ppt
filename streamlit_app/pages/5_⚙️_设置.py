"""Settings page for backend configuration."""

import sys
from pathlib import Path

import streamlit as st

# Add parent directory to path for imports
sys.path.insert(0, str(Path(__file__).parent.parent))

from api_client import (
    APIError,
    get_llm_settings,
    get_reflection_settings,
    reset_reflection_settings,
    update_llm_settings,
    update_reflection_settings,
)

st.set_page_config(
    page_title="è®¾ç½® - HTML2PPT",
    page_icon="âš™ï¸",
    layout="centered",
)

# Provider options
PROVIDERS = [
    {"value": "openai", "label": "OpenAI / OpenAIå…¼å®¹"},
    {"value": "gemini", "label": "Google Gemini"},
    {"value": "azure_openai", "label": "Azure OpenAI"},
]

PRESET_MODELS = {
    "openai": ["gpt-4o", "gpt-4o-mini", "o1", "o1-mini"],
    "gemini": [
        "gemini-2.5-pro",
        "gemini-2.5-flash",
        "gemini-2.5-flash-lite",
        "gemini-2.0-flash",
        "gemini-2.0-flash-lite",
    ],
    "azure_openai": ["gpt-4o", "gpt-4o-mini", "gpt-4-turbo"],
}


# Load settings
@st.cache_data(ttl=60)
def load_settings() -> dict:
    return get_llm_settings()


@st.cache_data(ttl=60)
def load_reflection() -> dict:
    return get_reflection_settings()


settings = load_settings()

# Header
st.title("âš™ï¸ è®¾ç½®")
st.caption("é…ç½®LLMåç«¯å’Œç”Ÿæˆå‚æ•°ï¼ˆå«å¯é€‰çš„åæ€å®¡æŸ¥ï¼‰")

# Settings form
with st.form("settings_form"):
    # Provider
    provider_options = [p["value"] for p in PROVIDERS]
    provider_labels = [p["label"] for p in PROVIDERS]

    current_provider_idx = (
        provider_options.index(settings.get("provider", "openai"))
        if settings.get("provider") in provider_options
        else 0
    )

    provider = st.selectbox(
        "LLM æä¾›å•†",
        options=provider_options,
        format_func=lambda x: dict(zip(provider_options, provider_labels))[x],
        index=current_provider_idx,
    )

    # Model
    preset_models = PRESET_MODELS.get(provider, [])
    current_model = settings.get("model", "gpt-4o")

    model = st.text_input("æ¨¡å‹", value=current_model, help="å¯ç›´æ¥è¾“å…¥æ¨¡å‹åç§°ï¼›æ¨èä½¿ç”¨ GPT-4o æˆ– Gemini 2.5 ç³»åˆ—")

    # Preset model buttons
    if preset_models:
        st.caption("æ¨èæ¨¡å‹ï¼š")
        cols = st.columns(len(preset_models))
        for i, m in enumerate(preset_models):
            with cols[i]:
                if st.form_submit_button(m, use_container_width=True):
                    model = m

    # Base URL
    base_url = st.text_input(
        "è‡ªå®šä¹‰APIç«¯ç‚¹ (å¯é€‰)",
        value=settings.get("base_url", ""),
        placeholder="ä¾‹å¦‚: http://localhost:11434/v1 (Ollama)",
        help="ç•™ç©ºä½¿ç”¨å®˜æ–¹APIï¼Œæˆ–å¡«å†™è‡ªå®šä¹‰ç«¯ç‚¹å¦‚vLLMã€Ollamaã€OpenRouterç­‰",
    )

    # Temperature
    temperature = st.slider(
        "Temperature",
        min_value=0.0,
        max_value=2.0,
        value=settings.get("temperature", 0.7),
        step=0.1,
        help="è¾ƒä½å€¼æ›´ç²¾ç¡®ï¼Œè¾ƒé«˜å€¼æ›´æœ‰åˆ›æ„",
    )

    col1, col2, col3 = st.columns(3)
    with col1:
        st.caption("ç²¾ç¡® (0)")
    with col2:
        st.caption("å¹³è¡¡ (0.7)")
    with col3:
        st.caption("åˆ›æ„ (2)")

    # Max tokens
    max_tokens = st.number_input(
        "æœ€å¤§Tokenæ•°",
        min_value=256,
        max_value=32000,
        value=settings.get("max_tokens", 4096),
        step=256,
    )

    # Submit
    submitted = st.form_submit_button("ğŸ’¾ ä¿å­˜è®¾ç½®", use_container_width=True, type="primary")

    if submitted:
        new_settings = {
            "provider": provider,
            "model": model,
            "temperature": temperature,
            "max_tokens": max_tokens,
        }
        if base_url.strip():
            new_settings["base_url"] = base_url.strip()

        try:
            update_llm_settings(new_settings)
            load_settings.clear()  # Clear cache
            st.success("âœ… è®¾ç½®å·²ä¿å­˜")
        except APIError as e:
            st.error(f"ä¿å­˜å¤±è´¥: {e.detail}")

st.divider()
st.header("ğŸ” Reflection å®¡æŸ¥ï¼ˆå¯é€‰ï¼‰")
st.caption("ç”¨äºç”Ÿæˆåé€é¡µå¿«é€Ÿè§„åˆ™æ ¡éªŒ + å¯é€‰ LLM å¤æ ¸ï¼Œå¿…è¦æ—¶è§¦å‘é‡å†™ï¼›é»˜è®¤å…³é—­ã€‚")

try:
    reflection_settings = load_reflection()
except APIError as e:
    reflection_settings = None
    st.warning(f"æ— æ³•è¯»å– Reflection è®¾ç½®: {e.detail}")

if reflection_settings:
    base = reflection_settings.get("base") or {}
    override = reflection_settings.get("override") or None
    effective = reflection_settings.get("effective") or {}
    overridden_fields = reflection_settings.get("overridden_fields") or []

    if override:
        st.info(f"å½“å‰å­˜åœ¨è¿è¡Œæ—¶è¦†ç›–å­—æ®µ: {', '.join(overridden_fields) if overridden_fields else '(æœªçŸ¥)'}")

    with st.form("reflection_form"):
        enabled = st.toggle("å¯ç”¨ Reflection å®¡æŸ¥", value=bool(effective.get("enabled", False)))

        st.subheader("é€é¡µå®¡æŸ¥")
        per_slide_max_rewrites = st.number_input(
            "é€é¡µæœ€å¤§é‡å†™æ¬¡æ•°",
            min_value=0,
            max_value=5,
            value=int(effective.get("per_slide_max_rewrites", 2)),
            step=1,
            help="æ¯é¡µæœ€å¤šå…è®¸è¢«æ‰“å›å¹¶é‡å†™çš„æ¬¡æ•°ï¼›è¶…è¿‡åé™çº§ä¿ç•™æœ€åç‰ˆæœ¬å¹¶è®°å½• warningsã€‚",
        )

        enable_llm_review = st.toggle(
            "å¯ç”¨ LLM å¤æ ¸ï¼ˆJudgeï¼‰",
            value=bool(effective.get("enable_llm_review", True)),
        )
        evaluator_temperature = st.slider(
            "Judge Temperature",
            min_value=0.0,
            max_value=2.0,
            value=float(effective.get("evaluator_temperature", 0.1)),
            step=0.1,
        )

        st.subheader("é™æ€è§„åˆ™")
        col1, col2 = st.columns(2)
        with col1:
            enable_rule_text_density = st.toggle(
                "æ–‡æœ¬å¯†åº¦é™åˆ¶",
                value=bool(effective.get("enable_rule_text_density", True)),
            )
            text_char_limit = st.number_input(
                "å•é¡µæ–‡æœ¬å­—ç¬¦ä¸Šé™ï¼ˆä¼°ç®—ï¼‰",
                min_value=0,
                max_value=5000,
                value=int(effective.get("text_char_limit", 900)),
                step=50,
                help="è¿‘ä¼¼å¯è§æ–‡æœ¬å­—ç¬¦æ•°ä¸Šé™ï¼ˆéæ¸²æŸ“çº§ç»Ÿè®¡ï¼‰ã€‚",
            )
        with col2:
            enable_rule_point_density = st.toggle(
                "è¦ç‚¹å¯†åº¦é™åˆ¶",
                value=bool(effective.get("enable_rule_point_density", True)),
            )
            max_points_per_slide = st.number_input(
                "å•é¡µè¦ç‚¹æ•°ä¸Šé™ï¼ˆä¼°ç®—ï¼‰",
                min_value=0,
                max_value=20,
                value=int(effective.get("max_points_per_slide", 8)),
                step=1,
            )
            max_chars_per_point = st.number_input(
                "å•ä¸ªè¦ç‚¹å­—ç¬¦ä¸Šé™ï¼ˆä¼°ç®—ï¼‰",
                min_value=0,
                max_value=1000,
                value=int(effective.get("max_chars_per_point", 120)),
                step=10,
            )

        enable_rule_root_container = st.toggle(
            "å¼ºåŒ–æ ¹å®¹å™¨ç»“æ„çº¦æŸï¼ˆå¤ç”¨ç°æœ‰æ ¡éªŒï¼‰",
            value=bool(effective.get("enable_rule_root_container", True)),
        )

        st.subheader("å…¨å±€å®¡æŸ¥")
        enable_global_review = st.toggle(
            "å¯ç”¨å…¨å±€å®¡æŸ¥ï¼ˆDeck-levelï¼‰",
            value=bool(effective.get("enable_global_review", False)),
        )
        global_max_rewrite_passes = st.number_input(
            "å…¨å±€æœ€å¤§é‡å†™è½®æ¬¡",
            min_value=0,
            max_value=3,
            value=int(effective.get("global_max_rewrite_passes", 1)),
            step=1,
        )

        saved = st.form_submit_button("ğŸ’¾ ä¿å­˜ Reflection è®¾ç½®", use_container_width=True, type="primary")
        if saved:
            patch = {
                "enabled": enabled,
                "per_slide_max_rewrites": per_slide_max_rewrites,
                "enable_llm_review": enable_llm_review,
                "enable_rule_text_density": enable_rule_text_density,
                "text_char_limit": text_char_limit,
                "enable_rule_point_density": enable_rule_point_density,
                "max_points_per_slide": max_points_per_slide,
                "max_chars_per_point": max_chars_per_point,
                "enable_rule_root_container": enable_rule_root_container,
                "evaluator_temperature": evaluator_temperature,
                "enable_global_review": enable_global_review,
                "global_max_rewrite_passes": global_max_rewrite_passes,
            }

            try:
                update_reflection_settings(patch)
                load_reflection.clear()
                st.success("âœ… Reflection è®¾ç½®å·²ä¿å­˜ï¼ˆè¿è¡Œæ—¶è¦†ç›–ï¼‰")
            except APIError as e:
                st.error(f"ä¿å­˜å¤±è´¥: {e.detail}")

    if st.button("ğŸ§¹ æ¸…é™¤è¿è¡Œæ—¶è¦†ç›–ï¼ˆæ¢å¤ env é»˜è®¤ï¼‰", use_container_width=True):
        try:
            reset_reflection_settings()
            load_reflection.clear()
            st.success("âœ… å·²æ¸…é™¤è¿è¡Œæ—¶è¦†ç›–")
        except APIError as e:
            st.error(f"æ¸…é™¤å¤±è´¥: {e.detail}")

# Info box
st.divider()
st.info(
    """
**æç¤º**
- API å¯†é’¥éœ€è¦åœ¨æœåŠ¡å™¨ç«¯çš„ `.env` æ–‡ä»¶ä¸­é…ç½®
- å¯ä½¿ç”¨è‡ªå®šä¹‰æ¨¡å‹åç§°ä»¥å…¼å®¹å„ç±» OpenAI å…¼å®¹æœåŠ¡
- OpenAI å…¼å®¹ç«¯ç‚¹æ”¯æŒ vLLMã€Ollamaã€OpenRouter ç­‰æ–¹æ¡ˆ
- Reflection è®¾ç½®ä¸ºè¿è¡Œæ—¶è¦†ç›–ï¼šé‡å¯æœåŠ¡åä¼šæ¢å¤ä¸º `.env` é»˜è®¤å€¼
"""
)
